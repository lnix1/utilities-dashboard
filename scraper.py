#--------------------------------------------------------------------#
# Trying a headleass browser approach instead. For linux, this 
# required downloading chromium and placing the chrome driver
# in /usr/bin
# Basically follow the 'For Linux' comment here:
# https://stackoverflow.com/questions/8255929/running-selenium-webdriver-python-bindings-in-chrome
#
# Selenium documentation could also be useful:
# https://selenium-python.readthedocs.io/locating-elements.html
#--------------------------------------------------------------------#

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import os
import pandas as pd
from bs4 import BeautifulSoup
import re
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC

def AmazonWebDriver(username, password, zip_code, order_date):
   chrome_options = Options()
   chrome_options.add_argument('--window-size=1920x1080')
   chrome_options.add_argument('--headless')
   driver = webdriver.Chrome(chrome_options=chrome_options)
   driver.get('https://primenow.amazon.com/home')
   driver.find_element_by_id('lsPostalCode').send_keys(zip_code) 
   driver.find_element_by_class_name('a-button-input').click()
   wait = WebDriverWait(driver, 10)
   element = wait.until(EC.element_to_be_clickable((By.XPATH, "(//div[@class='show-for-large page_header_drop_menu_trigger__triggerText__3dDUD'])[3]")))
   driver.find_element_by_xpath("(//div[@class='show-for-large page_header_drop_menu_trigger__triggerText__3dDUD'])[3]").click()
   driver.find_element_by_id('ap_email').send_keys(username)  
   driver.find_element_by_id('ap_password').send_keys(password)
   driver.find_element_by_id('signInSubmit').click()
   driver.find_element_by_xpath("(//a[@class='a-spacing-small a-link-normal'])[1]").click()
   # Pull all of the tables from the html with the order dates
   order_dates_page = driver.page_source
   order_dates_page_soup = BeautifulSoup(order_dates_page)
   order_dates_table = order_dates_page_soup.find_all('table')
   # Parse the order dates available to find the correct number corresponding to the autogenerated btn id
   i = 0
   btn_id = 0
   order_found = False
   while order_found == False:
      order_found = order_dates_table[i].find('span').text.strip('\n').strip() in order_date 
      if order_found == False:
         i += 1
         btn_id += 2
   driver.find_element_by_id('a-autoid-'+str(btn_id)+'-announce').click()
   order_page_source = driver.page_source
   driver.quit()
   return order_page_source;

# Create the function for extracthing the order table from a given order page selected by the user
def OrderTableExtractor(html_source):
   order_soup = BeautifulSoup(html_source)
   # Grab the table on the right of the page with the items ordered
   order_container = order_soup.find('div', class_ = 'a-column a-span5 a-span-last')
   # Break the order table out by the individual items, placing the the html for each as an item in a list
   order_containers = order_container.find_all('div', class_ = 'a-box-inner')
   # Initialize a table to fill with the order informationorder_summary_table_test = GetOrderSummary(order_page_html)
   order_data_columns = ['item_name', 'qty/wgt', 'by_unit_wgt', 'unit_price', 'item_url']
   order_data_frame = pd.DataFrame(columns=order_data_columns)
   # Iterate over the order items and extract the desired information, placing it into a table
   for o in order_containers[1:len(order_containers)]:
      # Grab and format the order url 
      item_url_end = o.find('a').get('href')
      amazon_url_base = 'https://www.amazon.com'
      item_url = amazon_url_base + item_url_end
      # Grab the item name and reformat
      item_name = o.find('span').text.strip('\n').strip()
      # Extract all of the text from the grocery item cell
      e = o.find_all('span')
      # We can use the contents of the second <span> container to determine whether we are dealing with 'by unit' or 'by weight' items
      # 'by unit' items will contain 'Qty' while 'by weight' items will contain 'per pound'
      # The first two possible cases (for items priced by count w/ or w/o replacement) are treated the same
      if 'Qty' in e[1].text:
         # Extract the quantity and unit price
         qnty_wgt_unit_price = e[1].text.split()
         # Append both of the features to the relevant vectors
         qty_wgt = qnty_wgt_unit_price[1]
         unit_price = qnty_wgt_unit_price[2]
         # Append a label specifying that this item was priced by unit
         by_unit_wgt = 'by unit'
      # The second two possible cases (for items bought by weight w/ or w/o replacement) are treated the same
      else:
         # Extract and append per_unit price
         unit_price = re.sub('[a-z]', '', e[1].text.strip('\n').strip()).strip()
         # Extract and append weight
         qty_wgt = re.sub('[a-z]', '', e[6].text.strip('\n').strip()).strip()
         # Append a label specifying that this item was priced by weight
         by_unit_wgt = 'by weight' + ' (' + re.sub(r'\d+', '', e[1].text.strip('\n').strip()).strip('$').strip('.').strip() + ')'
      new_order_row = pd.DataFrame({'item_name':[item_name], 'qty/wgt': [qty_wgt], 'by_unit_wgt': [by_unit_wgt], 'unit_price': [unit_price], 'item_url': [item_url]})
      order_data_frame = order_data_frame.append(new_order_row, ignore_index=True)
   return order_data_frame;

def GetOrderSummary(html_source):
   summary_soup = BeautifulSoup(html_source)
   summary_container = summary_soup.find_all('div', class_ = 'a-column a-span5')
   order_summary_table = pd.DataFrame({
    'order_date': [summary_container[0].find_all('span', id='browser-order-status-order-date')[0].text.strip('\n').strip().strip('Order date: ')],
    'order_number': [summary_container[0].find_all('span', id='browser-order-status-order-number')[0].text.strip('\n').strip().strip('Order #: ')],
    'item_total': [summary_container[0].find_all('span', id='checkout-order-totals-items-field')[0].text.strip('\n').strip()],
    'delivery_fee': [summary_container[0].find_all('span', id='checkout-order-totals-deliveryFee-field')[0].text.strip('\n').strip()],
    'tip': [summary_container[0].find_all('span', id='checkout-order-totals-tip-field')[0].text.strip('\n').strip()],
    'order_total': [summary_container[0].find_all('span', id='checkout-total-price-field')[0].text.strip('\n').strip()]})
   return order_summary_table;
#-------------------------------------------------------------------#



#-------------------------------------------------------------------#
# Initialize a few values to test the models with 
zip_code = 'my zip code'
order_date = 'Jan 14 2020'
username = 'my amazon primenow email'
password = 'my amazon primenow password'

# Call the Web driver to test
order_page_html = AmazonWebDriver(username, password, zip, order_date)

# Call the function to test and extract a table for the Mar. 5th grocery order
order_data_frame2 = OrderTableExtractor(order_page_html)

order_data_frame2.to_csv(r'groceries_itemized_Jan_14_2020.csv', index = False, header=True)

# Call the order summary function to test
order_summary_table_test = GetOrderSummary(order_page_html)

order_summary_table_test.to_csv(r'groceries_summary_Jan_22_2020.csv', index = False, header=True)
#--------------------------------------------------------------------#
